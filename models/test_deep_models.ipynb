{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4558152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Final-Project-TimeSeries-UTEC\", name=\"RandomForest-temp-spec\", config={\n",
    "    \"n_splits\": 7\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ad132",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df96c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size=354, num_classes=6):\n",
    "        super(MLPModel, self).__init__()\n",
    "        # Hidden layers with dropout decrecientes\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.35)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(64, num_classes)\n",
    "        \n",
    "        # weights init\n",
    "        self._initialize_weights()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # negative_slope ayuda a mantener el flujo de gradientes\n",
    "        x = F.selu(self.fc1(x)) \n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.selu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.selu(self.fc3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        return self.output(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Método para compatibilidad con sklearn-style\"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return F.softmax(logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight, gain=1.0)  # Inicialización ortogonal\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.01)  # Pequeño bias inicial\n",
    "    \n",
    "class LSTMModel(nn.Module): \n",
    "    def __init__(self, input_size=354, num_classes=6, hidden_size=128, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Capa LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  # Para que la entrada sea (batch, seq, feature)\n",
    "            dropout=0.3 if num_classes > 1 else 0,  # Dropout entre capas LSTM\n",
    "            #bidirectional=True  # Bidireccional para capturar mejor la temporalidad\n",
    "        )\n",
    "        \n",
    "        # Capas de atencion\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Capas fully connected\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x debe tener forma (batch_size, seq_length, input_size)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Aplicar atención\n",
    "        attn_weights = self.attention(lstm_out)\n",
    "        attn_weights = attn_weights.squeeze(2) \n",
    "        attn_weights = F.softmax(attn_weights, dim=1)  # Normalizar pesos de atención\n",
    "        attn_output = torch.bmm(attn_weights.unsqueeze(1), lstm_out).squeeze(1)  # (batch_size, hidden_size)\n",
    "        \n",
    "        # Capas fully connected\n",
    "        x = F.relu(self.fc1(attn_output))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=6, input_features=354):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Calcula el tamaño de entrada a fc1 automáticamente\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, input_channels, input_features)\n",
    "            dummy = self.conv1(dummy)\n",
    "            dummy = self.conv2(dummy)\n",
    "            dummy = self.conv3(dummy)\n",
    "            self._to_linear = dummy.view(1, -1).shape[1]\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        elif x.dim() == 3 and x.size(1) != 1:\n",
    "            x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d1d7f",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0253f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.base import clone as sk_clone\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    #if epoch is not None:\n",
    "    #    wandb.log({\"train_loss\": epoch_loss, \"epoch\": epoch})\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    \n",
    "    eval_time = time.time() - start_time\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metrics = {\n",
    "        'f1': f1_score(all_labels, all_preds, average='weighted'),\n",
    "        'bal_acc': balanced_accuracy_score(all_labels, all_preds),\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'roc_auc': roc_auc_score(\n",
    "            label_binarize(all_labels, classes=np.unique(all_labels)),\n",
    "            all_probs,\n",
    "            multi_class='ovr'\n",
    "        ) if len(np.unique(all_labels)) > 2 else roc_auc_score(all_labels, all_probs[:, 1]),\n",
    "        'eval_time': eval_time\n",
    "    }\n",
    "    \n",
    "    return metrics, all_preds, all_probs, all_labels\n",
    "\n",
    "\n",
    "\n",
    "def train_and_test_deepmodel(model, X_train, y_train, X_test, y_test, model_name, dataset_name, save_path, epochs):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Preparar DataLoaders\n",
    "    train_ds = TensorDataset(torch.FloatTensor(X_train.values), torch.LongTensor(y_train.values))\n",
    "    test_ds = TensorDataset(torch.FloatTensor(X_test.values), torch.LongTensor(y_test.values))\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=256)\n",
    "    \n",
    "    # Entrenamiento\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_start = time.time()\n",
    "    for epoch in range(epochs):  # 10 épocas por defecto\n",
    "        train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_time = time.time() - train_start\n",
    "    \n",
    "    # Evaluación\n",
    "    eval_start = time.time()\n",
    "    metrics, _, _, _ = evaluate(model, test_loader, device)\n",
    "    eval_time = time.time() - eval_start\n",
    "    \n",
    "    # Guardar modelo\n",
    "    filename = f\"{model_name.lower()}_features_{dataset_name.lower()}.pth\"\n",
    "    torch.save(model.state_dict(), os.path.join(save_path, filename))\n",
    "    \n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'F1-score': metrics['f1'],\n",
    "        'Balanced accuracy': metrics['bal_acc'],\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'ROC-AUC': metrics['roc_auc'],\n",
    "        'Tiempo entrenamiento (s)': train_time,\n",
    "        'Tiempo predicción (s)': eval_time,\n",
    "        'Tiempo total (s)': train_time + eval_time,\n",
    "        'Archivo': filename\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_mlp(X, y, name_model ,model_class, model_kwargs, epochs=10, batch_size=128, n_splits=7, device='cpu'):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Resultados a recolectar (formato consistente con modelos clásicos)\n",
    "    results = {\n",
    "        'Modelo': name_model,\n",
    "        'F1-score': [],\n",
    "        'Balanced accuracy': [],\n",
    "        'Accuracy': [],\n",
    "        'ROC-AUC': [],\n",
    "        'Tiempo fold (s)': []\n",
    "    }\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        # Inicializar modelo\n",
    "        model = model_class(**model_kwargs).to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Preparar DataLoaders\n",
    "        train_ds = TensorDataset(torch.FloatTensor(X[train_idx]), torch.LongTensor(y[train_idx]))\n",
    "        val_ds = TensorDataset(torch.FloatTensor(X[val_idx]), torch.LongTensor(y[val_idx]))\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size*2)\n",
    "        \n",
    "        # Entrenamiento\n",
    "        train_time = 0\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            train_time += time.time() - epoch_start\n",
    "            \n",
    "        # Evaluación\n",
    "        eval_start = time.time()\n",
    "        metrics, _, _, _ = evaluate(model, val_loader, device)\n",
    "        eval_time = time.time() - eval_start\n",
    "        \n",
    "        # Calcular tiempo total del fold (entrenamiento + evaluación)\n",
    "        fold_time = time.time() - fold_start_time\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results['F1-score'].append(metrics['f1'])\n",
    "        results['Balanced accuracy'].append(metrics['bal_acc'])\n",
    "        results['Accuracy'].append(metrics['accuracy'])\n",
    "        results['ROC-AUC'].append(metrics['roc_auc'])\n",
    "        results['Tiempo fold (s)'].append(fold_time)\n",
    "    \n",
    "    # Crear DataFrame en formato consistente con modelos clásicos\n",
    "    df_results = pd.DataFrame({\n",
    "        'Modelo': results['Modelo'],\n",
    "        'F1-score': np.mean(results['F1-score']),\n",
    "        'Balanced accuracy': np.mean(results['Balanced accuracy']),\n",
    "        'Accuracy': np.mean(results['Accuracy']),\n",
    "        'ROC-AUC': np.mean(results['ROC-AUC']),\n",
    "        'Tiempo promedio (s)': np.mean(results['Tiempo fold (s)']),\n",
    "        'Tiempo total (s)': np.sum(results['Tiempo fold (s)'])\n",
    "    }, index=[0])\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27f08643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def setup_wandb(project_name=\"Final-Project-TimeSeries-UTEC\", model_type=\"traditional\"):\n",
    "    \"\"\"Configuración inicial de wandb para cualquier tipo de modelo\"\"\"\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        config={\n",
    "            \"model_type\": model_type,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "def log_results_to_wandb(results_df, dataset_type, evaluation_type):\n",
    "    \"\"\"\n",
    "    Loggear resultados a wandb de forma consistente para todos los modelos\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame con columnas estandarizadas\n",
    "        dataset_type: \"temporales\" o \"espectrales\"\n",
    "        evaluation_type: \"validación_cruzada\" o \"evaluación_test\"\n",
    "    \"\"\"\n",
    "    required_columns = {\n",
    "        'Modelo', 'F1-score', 'Balanced accuracy', 'Accuracy', 'ROC-AUC',\n",
    "        'Tiempo promedio (s)', 'Tiempo total (s)'\n",
    "    }\n",
    "    \n",
    "    # Verificar columnas requeridas\n",
    "    assert required_columns.issubset(results_df.columns), f\"Faltan columnas requeridas: {required_columns - set(results_df.columns)}\"\n",
    "    \n",
    "    # Loggear cada fila del DataFrame\n",
    "    for _, row in results_df.iterrows():\n",
    "        log_data = {\n",
    "            \"Modelo\": row[\"Modelo\"],\n",
    "            \"Dataset\": dataset_type,\n",
    "            \"Tipo\": evaluation_type,\n",
    "            \"F1-score\": row[\"F1-score\"],\n",
    "            \"Balanced_accuracy\": row[\"Balanced accuracy\"],\n",
    "            \"Accuracy\": row[\"Accuracy\"],\n",
    "            \"ROC-AUC\": row[\"ROC-AUC\"]\n",
    "        }\n",
    "        \n",
    "        # Añadir tiempos según el tipo de evaluación\n",
    "        if evaluation_type == \"validación_cruzada\":\n",
    "            log_data.update({\n",
    "                \"Tiempo_promedio(s)\": row[\"Tiempo promedio (s)\"],\n",
    "                \"Tiempo_total(s)\": row[\"Tiempo total (s)\"]\n",
    "            })\n",
    "        else:  # evaluación_test\n",
    "            log_data.update({\n",
    "                \"Tiempo_entrenamiento(s)\": row[\"Tiempo entrenamiento (s)\"],\n",
    "                \"Tiempo_predicción(s)\": row[\"Tiempo predicción (s)\"],\n",
    "                \"Tiempo_total(s)\": row[\"Tiempo total (s)\"]\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "    \n",
    "    # Loggear tabla resumen\n",
    "    wandb.log({\n",
    "        f\"Resumen_{evaluation_type}_{dataset_type}\": wandb.Table(dataframe=results_df)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729bce51",
   "metadata": {},
   "source": [
    "# Train_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12be6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_splits = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234815e",
   "metadata": {},
   "source": [
    "## Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4939853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(project_root, 'data')\n",
    "processed_path = data_path + '/processed'\n",
    "\n",
    "save_models_path = os.path.join(project_root, 'models', 'save_models')\n",
    "save_results_path = os.path.join(project_root, 'models', 'results')\n",
    "\n",
    "features_temporal = pd.read_csv(processed_path + '/features_temporales_labelNum_overlap50.csv')\n",
    "features_espectrales = pd.read_csv(processed_path + '/features_espectrales_labelNum_overlap50.csv')\n",
    "\n",
    "X_temp = features_temporal.iloc[:, 1:-1] \n",
    "y_temp = features_temporal.iloc[:, -1]  \n",
    "X_spec = features_espectrales.iloc[:, 1:-1] \n",
    "y_spec = features_espectrales.iloc[:, -1]  \n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_temp_train, X_temp_test, y_temp_train, y_temp_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "X_spec_train, X_spec_test, y_spec_train, y_spec_test = train_test_split(X_spec, y_spec, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86aed903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kfold_temp = kfold_mlp(X_temp_train.values, y_temp_train.values, \n",
    "                         \"MLP\",MLPModel, \n",
    "                         {'input_size': X_temp_train.shape[1], 'num_classes': len(np.unique(y_temp_train))},\n",
    "                         epochs=epochs, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "df_kfold_spec = kfold_mlp(X_spec_train.values, y_temp_train.values, \n",
    "                         \"MLP\",MLPModel, \n",
    "                         {'input_size': X_spec_train.shape[1], 'num_classes': len(np.unique(y_spec_train))},\n",
    "                         epochs=epochs, device='cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1907b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Tiempo promedio (s)</th>\n",
       "      <th>Tiempo total (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.883374</td>\n",
       "      <td>0.820624</td>\n",
       "      <td>0.888606</td>\n",
       "      <td>0.979886</td>\n",
       "      <td>5.835734</td>\n",
       "      <td>40.850136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo  F1-score  Balanced accuracy  Accuracy   ROC-AUC  \\\n",
       "0    MLP  0.883374           0.820624  0.888606  0.979886   \n",
       "\n",
       "   Tiempo promedio (s)  Tiempo total (s)  \n",
       "0             5.835734         40.850136  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kfold_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ede7d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Tiempo promedio (s)</th>\n",
       "      <th>Tiempo total (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.871793</td>\n",
       "      <td>0.817565</td>\n",
       "      <td>0.880811</td>\n",
       "      <td>0.97639</td>\n",
       "      <td>5.842845</td>\n",
       "      <td>40.899913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo  F1-score  Balanced accuracy  Accuracy  ROC-AUC  Tiempo promedio (s)  \\\n",
       "0    MLP  0.871793           0.817565  0.880811  0.97639             5.842845   \n",
       "\n",
       "   Tiempo total (s)  \n",
       "0         40.899913  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kfold_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bcf0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_cv_temp = os.path.join(save_results_path, 'resultados_cv_temporales.csv')\n",
    "if os.path.isfile(csv_cv_temp):\n",
    "    df_cv_temp_old = pd.read_csv(csv_cv_temp)\n",
    "    df_temp_kfold = pd.concat([df_cv_temp_old, df_kfold_temp], ignore_index=True)\n",
    "df_temp_kfold.to_csv(csv_cv_temp, index=False)\n",
    "\n",
    "csv_cv_spec = os.path.join(save_results_path, 'resultados_cv_espectrales.csv')\n",
    "if os.path.isfile(csv_cv_spec):\n",
    "    df_cv_spec_old = pd.read_csv(csv_cv_spec)\n",
    "    df_spec_kfold = pd.concat([df_cv_spec_old, df_kfold_spec], ignore_index=True)\n",
    "df_spec_kfold.to_csv(csv_cv_spec, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_results_to_wandb(df_kfold_temp, \"temporales\", \"validación_cruzada\")\n",
    "log_results_to_wandb(df_kfold_temp, \"espectrales\", \"validación_cruzada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40302290",
   "metadata": {},
   "source": [
    "# Training-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "981b0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_results_temp = train_and_test_deepmodel(\n",
    "    model=MLPModel(input_size=X_temp_train.shape[1], num_classes=6),\n",
    "    X_train=X_temp_train,\n",
    "    y_train=y_temp_train,\n",
    "    X_test=X_temp_test,\n",
    "    y_test=y_temp_test,\n",
    "    model_name=\"MLP\",\n",
    "    dataset_name=\"temporales\",\n",
    "    save_path=save_models_path,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "dict_test_results_spec = train_and_test_deepmodel(\n",
    "    model=MLPModel(input_size=X_spec_train.shape[1], num_classes=6),\n",
    "    X_train=X_spec_train,\n",
    "    y_train=y_spec_train,\n",
    "    X_test=X_spec_test,\n",
    "    y_test=y_spec_test,\n",
    "    model_name=\"MLP\",\n",
    "    dataset_name=\"espectrales\",\n",
    "    save_path=save_models_path,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f9689ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'MLP',\n",
       " 'F1-score': 0.8888468250636777,\n",
       " 'Balanced accuracy': 0.832601981309999,\n",
       " 'Accuracy': 0.8951048951048951,\n",
       " 'ROC-AUC': 0.9815525079627383,\n",
       " 'Tiempo entrenamiento (s)': 6.182087421417236,\n",
       " 'Tiempo predicción (s)': 0.04358339309692383,\n",
       " 'Tiempo total (s)': 6.22567081451416,\n",
       " 'Archivo': 'mlp_features_temporales.pth'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test_results_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f0c16b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Modelo': 'MLP',\n",
       " 'F1-score': 0.8672343363334757,\n",
       " 'Balanced accuracy': 0.8032980908902747,\n",
       " 'Accuracy': 0.8782051282051282,\n",
       " 'ROC-AUC': 0.9766339849830432,\n",
       " 'Tiempo entrenamiento (s)': 9.73764419555664,\n",
       " 'Tiempo predicción (s)': 0.04715704917907715,\n",
       " 'Tiempo total (s)': 9.784801244735718,\n",
       " 'Archivo': 'mlp_features_espectrales.pth'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test_results_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c08653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_test_temp = os.path.join(save_results_path, \"resultados_test_temporales.csv\")\n",
    "\n",
    "# Crear DataFrame con los resultados del MLP\n",
    "mlp_test_results_temp = {\n",
    "    \"Modelo\": \"MLP\",\n",
    "    \"F1-score\": dict_test_results_temp[\"F1-score\"],\n",
    "    \"Balanced accuracy\": dict_test_results_temp[\"Balanced accuracy\"],\n",
    "    \"Accuracy\": dict_test_results_temp[\"Accuracy\"],\n",
    "    \"ROC-AUC\": dict_test_results_temp[\"ROC-AUC\"],\n",
    "    \"Tiempo entrenamiento (s)\": dict_test_results_temp[\"Tiempo entrenamiento (s)\"],\n",
    "    \"Tiempo predicción (s)\": dict_test_results_temp[\"Tiempo predicción (s)\"],\n",
    "    \"Tiempo total (s)\": dict_test_results_temp[\"Tiempo total (s)\"],\n",
    "    \"Archivo\": dict_test_results_temp[\"Archivo\"]\n",
    "}\n",
    "\n",
    "# Leer archivo existente o crear nuevo DataFrame\n",
    "if os.path.isfile(csv_test_temp):\n",
    "    df_test_temp = pd.read_csv(csv_test_temp)\n",
    "    # Eliminar entrada previa de MLP si existe (para evitar duplicados)\n",
    "    df_test_temp = df_test_temp[df_test_temp['Modelo'] != 'MLP']\n",
    "else:\n",
    "    df_test_temp = pd.DataFrame()\n",
    "\n",
    "# Concatenar los nuevos resultados\n",
    "df_test_temp = pd.concat([df_test_temp, pd.DataFrame([mlp_test_results_temp])], ignore_index=True)\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "df_test_temp.to_csv(csv_test_temp, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_mlp_temp = pd.DataFrame([mlp_test_results_temp])\n",
    "log_results_to_wandb(df_test_mlp_temp, \"temporales\", \"evaluación_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab6679c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_spec = os.path.join(save_results_path, \"resultados_test_espectrales.csv\")\n",
    "# Crear DataFrame con los resultados del MLP\n",
    "mlp_test_results_spec = {\n",
    "    \"Modelo\": \"MLP\",\n",
    "    \"F1-score\": dict_test_results_spec[\"F1-score\"],\n",
    "    \"Balanced accuracy\": dict_test_results_spec[\"Balanced accuracy\"],\n",
    "    \"Accuracy\": dict_test_results_spec[\"Accuracy\"],\n",
    "    \"ROC-AUC\": dict_test_results_spec[\"ROC-AUC\"],\n",
    "    \"Tiempo entrenamiento (s)\": dict_test_results_spec[\"Tiempo entrenamiento (s)\"],\n",
    "    \"Tiempo predicción (s)\": dict_test_results_spec[\"Tiempo predicción (s)\"],\n",
    "    \"Tiempo total (s)\": dict_test_results_spec[\"Tiempo total (s)\"],\n",
    "    \"Archivo\": dict_test_results_spec[\"Archivo\"]\n",
    "}\n",
    "\n",
    "# Leer archivo existente o crear nuevo DataFrame\n",
    "if os.path.isfile(csv_test_spec):\n",
    "    df_test_spec = pd.read_csv(csv_test_spec)\n",
    "    # Eliminar entrada previa de MLP si existe (para evitar duplicados)\n",
    "    df_test_spec = df_test_spec[df_test_spec['Modelo'] != 'MLP']\n",
    "else:\n",
    "    df_test_spec = pd.DataFrame()\n",
    "\n",
    "# Concatenar los nuevos resultados\n",
    "df_test_spec = pd.concat([df_test_spec, pd.DataFrame([mlp_test_results_spec])], ignore_index=True)\n",
    "\n",
    "# Guardar el archivo actualizado\n",
    "df_test_spec.to_csv(csv_test_spec, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b751b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_mlp_spec = pd.DataFrame([mlp_test_results_spec])\n",
    "log_results_to_wandb(df_test_mlp_spec, \"espectrales\", \"evaluación_test\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
